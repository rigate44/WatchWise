{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Dot\n",
    "from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('ratings_small.csv')\n",
    "ratings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan carlos\\AppData\\Local\\Temp\\ipykernel_8392\\2982561343.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv('movies_metadata.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157336</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24428</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>1997-08-20</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45462</th>\n",
       "      <td>122662</td>\n",
       "      <td>マルドゥック・スクランブル 排気</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45463</th>\n",
       "      <td>2012-09-29</td>\n",
       "      <td>[{'iso_639_1': 'ja', 'name': '日本語'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45464</th>\n",
       "      <td>249260</td>\n",
       "      <td>Avalanche Sharks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45465</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45466 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                            original_title    year  \\\n",
       "0           27205                                 Inception  2010.0   \n",
       "1             155                           The Dark Knight  2008.0   \n",
       "2          157336                              Interstellar  2014.0   \n",
       "3           24428                              The Avengers  2012.0   \n",
       "4           19995                                    Avatar  2009.0   \n",
       "...           ...                                       ...     ...   \n",
       "45461  1997-08-20  [{'iso_639_1': 'en', 'name': 'English'}]     NaN   \n",
       "45462      122662                          マルドゥック・スクランブル 排気     NaN   \n",
       "45463  2012-09-29      [{'iso_639_1': 'ja', 'name': '日本語'}]     NaN   \n",
       "45464      249260                          Avalanche Sharks     NaN   \n",
       "45465  2014-01-01  [{'iso_639_1': 'en', 'name': 'English'}]     NaN   \n",
       "\n",
       "       vote_average  \n",
       "0              4.05  \n",
       "1              4.15  \n",
       "2              4.05  \n",
       "3              3.70  \n",
       "4              3.60  \n",
       "...             ...  \n",
       "45461           NaN  \n",
       "45462           NaN  \n",
       "45463           NaN  \n",
       "45464           NaN  \n",
       "45465           NaN  \n",
       "\n",
       "[45466 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv('movies_metadata.csv')\n",
    "movies_df.columns\n",
    "movies_df = movies_df[['id', 'original_title', 'release_date', 'vote_average', 'vote_count']]\n",
    "movies_df['year'] = pd.to_datetime(movies_df['release_date'], errors='coerce').dt.year\n",
    "movies_df['vote_average'] = movies_df['vote_average'] / 2\n",
    "movies_df['vote_importance'] = movies_df['vote_average'] * movies_df['vote_count']\n",
    "movies_df = movies_df.sort_values('vote_importance', ascending=False)\n",
    "movies_df = movies_df[['id', 'original_title', 'year', 'vote_average']]\n",
    "movies_df.reset_index(drop=True, inplace=True)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 12.9292\n",
      "Epoch 2/5\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 2.8543\n",
      "Epoch 3/5\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 1.2991\n",
      "Epoch 4/5\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - loss: 0.9412\n",
      "Epoch 5/5\n",
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25b205f9e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = len(ratings_df['userId'].unique())\n",
    "num_movies = len(ratings_df['movieId'].unique())\n",
    "embedding_size = 50\n",
    "\n",
    "# Create mappings from userId and movieId to a continuous range of indices\n",
    "user_id_mapping = {id: idx for idx, id in enumerate(ratings_df['userId'].unique())}\n",
    "movie_id_mapping = {id: idx for idx, id in enumerate(ratings_df['movieId'].unique())}\n",
    "\n",
    "# Map the userId and movieId in the ratings DataFrame to the new indices\n",
    "ratings_df['userId'] = ratings_df['userId'].map(user_id_mapping)\n",
    "ratings_df['movieId'] = ratings_df['movieId'].map(movie_id_mapping)\n",
    "train_df['userId'] = train_df['userId'].map(user_id_mapping)\n",
    "train_df['movieId'] = train_df['movieId'].map(movie_id_mapping)\n",
    "test_df['userId'] = test_df['userId'].map(user_id_mapping)\n",
    "test_df['movieId'] = test_df['movieId'].map(movie_id_mapping)\n",
    "\n",
    "# Define the RecommenderNet class, inheriting from tf.keras.Model\n",
    "class RecommenderNet(Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        # Create embedding layers for users and movies\n",
    "        self.user_embedding = Embedding(num_users, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        self.movie_embedding = Embedding(num_movies, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        # Define a dot product layer to compute the similarity between user and movie embeddings\n",
    "        self.dot = Dot(axes=1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Get the embeddings for the users and movies\n",
    "        user_vector = self.user_embedding(inputs[0])\n",
    "        movie_vector = self.movie_embedding(inputs[1])\n",
    "        # Compute the dot product of the user and movie embeddings\n",
    "        dot_user_movie = self.dot([user_vector, movie_vector])\n",
    "        return dot_user_movie\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_movies': self.num_movies,\n",
    "            'embedding_size': self.embedding_size\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "    \n",
    "# model = RecommenderNet(num_users, num_movies, embedding_size)\n",
    "model = RecommenderNet(num_users, num_movies, embedding_size)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "train_user_ids = train_df['userId'].values\n",
    "train_movie_ids = train_df['movieId'].values\n",
    "train_ratings = train_df['rating'].values\n",
    "\n",
    "model.fit([train_user_ids, train_movie_ids], train_ratings, batch_size=64, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "RMSE: 1.12 MAE: 0.81 R2: -0.36\n"
     ]
    }
   ],
   "source": [
    "test_user_ids = test_df['userId'].values\n",
    "test_movie_ids = test_df['movieId'].values\n",
    "test_ratings = test_df['rating'].values\n",
    "\n",
    "predictions = model.predict([test_user_ids, test_movie_ids], batch_size=64, verbose=1)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(predictions, test_ratings))\n",
    "mae = mean_absolute_error(predictions, test_ratings)\n",
    "r2 = r2_score(predictions, test_ratings)\n",
    "\n",
    "print(f'RMSE: {rmse:.2f}', f'MAE: {mae:.2f}', f'R2: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{650:     movie_ids                                       movie_titles  \\\n",
       " 0       73290                            Raiders of the Lost Ark   \n",
       " 1        3181                                           Scarface   \n",
       " 2         969                                Mission: Impossible   \n",
       " 3        3030                                    Horrible Bosses   \n",
       " 4         318                                      Before Sunset   \n",
       " 5        3462                               Sleepless in Seattle   \n",
       " 6        1939                                          Backdraft   \n",
       " 7        2924                                       Frankenstein   \n",
       " 8        7075                                              Laura   \n",
       " 9          85                                     Stomp the Yard   \n",
       " 10      86882                           The Million Dollar Hotel   \n",
       " 11       7502                                              Dread   \n",
       " 12        858  Shriek If You Know What I Did Last Friday the ...   \n",
       " 13      27846                                          Baise-moi   \n",
       " 14       1212                                     Urban Explorer   \n",
       " 15       1193               Confession of a Child of the Century   \n",
       " 16       4103                                   End of the World   \n",
       " \n",
       "     predicted_ratings  \n",
       " 0            4.732871  \n",
       " 1            4.692942  \n",
       " 2            4.665102  \n",
       " 3            4.638840  \n",
       " 4            4.636364  \n",
       " 5            4.597427  \n",
       " 6            4.557642  \n",
       " 7            4.520934  \n",
       " 8            4.483932  \n",
       " 9            4.455853  \n",
       " 10           4.455190  \n",
       " 11           4.452798  \n",
       " 12           4.442741  \n",
       " 13           4.432067  \n",
       " 14           4.431914  \n",
       " 15           4.417721  \n",
       " 16           4.416930  }"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_predictions_for_users(user_ids, model, movie_id_mapping, movies_df, num_recommendations=50):\n",
    "    best_predictions = {}\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        # Create an array of all movie IDs\n",
    "        all_movie_ids = np.array(list(movie_id_mapping.values()))\n",
    "        \n",
    "        # Create an array of the user ID repeated for the number of movies\n",
    "        user_ids_array = np.array([user_id] * len(all_movie_ids))\n",
    "        \n",
    "        # Predict ratings for all movies for the given user\n",
    "        predictions = model.predict([user_ids_array, all_movie_ids], batch_size=64, verbose=0)\n",
    "        \n",
    "        # Get the top N movie indices with the highest predicted ratings\n",
    "        top_indices = predictions.flatten().argsort()[-num_recommendations:][::-1]\n",
    "        \n",
    "        # Map the indices back to movie IDs\n",
    "        top_movie_ids = [list(movie_id_mapping.keys())[i] for i in top_indices]\n",
    "        \n",
    "        # Get the movie titles for the top movie IDs\n",
    "        top_movie_titles = movies_df[movies_df['id'].astype(str).isin(map(str, top_movie_ids))]['original_title'].values\n",
    "        \n",
    "        # Ensure the lengths of top_movie_ids, top_movie_titles, and predictions[top_indices] are the same\n",
    "        min_length = min(len(top_movie_ids), len(top_movie_titles), len(predictions[top_indices].flatten()))\n",
    "        top_movie_ids = top_movie_ids[:min_length]\n",
    "        top_movie_titles = top_movie_titles[:min_length]\n",
    "        top_predictions = predictions[top_indices].flatten()[:min_length]\n",
    "        \n",
    "        # Store the top movie IDs, their titles, and their predicted ratings for the user\n",
    "        best_predictions[user_id] = pd.DataFrame({\n",
    "            'movie_ids': top_movie_ids,\n",
    "            'movie_titles': top_movie_titles,\n",
    "            'predicted_ratings': top_predictions\n",
    "        })\n",
    "    \n",
    "    return best_predictions\n",
    "\n",
    "# Example usage:\n",
    "user_ids = [650]  # Replace with actual user IDs\n",
    "best_predictions = get_best_predictions_for_users(user_ids, model, movie_id_mapping, movies_df)\n",
    "best_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99. Old"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
